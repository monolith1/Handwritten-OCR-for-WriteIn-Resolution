{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6455c4ee-7b1f-4994-aae2-00f87099e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20faf43f-a989-4aa4-be04-92dc0ac3340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_az_dataset(datasetPath):\n",
    "    # initialize the list of data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "    # loop over the rows of the A-Z handwritten digit dataset\n",
    "    for row in open(datasetPath):\n",
    "        # parse the label and image from the row\n",
    "        row = row.split(\",\")\n",
    "        label = int(row[0])\n",
    "        image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "        # images are represented as single channel (grayscale) images\n",
    "        # that are 28x28=784 pixels -- we need to take this flattened\n",
    "        # 784-d list of numbers and repshape them into a 28x28 matrix\n",
    "        image = image.reshape((28, 28))\n",
    "        # update the list of data and labels\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "    # convert the data and labels to NumPy arrays\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    labels = np.array(labels, dtype=\"int\")\n",
    "    # return a 2-tuple of the A-Z data and labels\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46c3569-60ee-4069-a91d-377da9b914d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "    # load the MNIST dataset and stack the training data and testing\n",
    "    # data together (we'll create our own training and testing splits\n",
    "    # later in the project)\n",
    "    ((trainData, trainLabels), (testData, testLabels)) = tf.keras.datasets.mnist.load_data()\n",
    "    data = np.vstack([trainData, testData])\n",
    "    labels = np.hstack([trainLabels, testLabels])\n",
    "    # return a 2-tuple of the MNIST data and labels\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f47cca-bb80-42ee-b5f7-8ef7cc1adfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(azData, azLabels) = load_az_dataset('data/NIST_SD19/A_Z Handwritten Data/A_Z Handwritten Data.csv')\n",
    "(digitsData, digitsLabels) = load_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88c5181-6b8e-4ad6-b500-321750738863",
   "metadata": {},
   "outputs": [],
   "source": [
    "azLabels += 10\n",
    "data = np.vstack([azData, digitsData])\n",
    "labels = np.hstack([azLabels, digitsLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50aa71d8-047a-4b76-8622-80b900748961",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = \"0123456789\"\n",
    "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c68418-dd4a-4a93-aaff-6bab354aee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [cv2.resize(image, (36, 36)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fbcaf52-5629-49f0-b907-2ea5177343bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)\n",
    "counts = labels.sum(axis=0)\n",
    "# account for skew in the labeled data\n",
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bddeccf2-0751-43e1-8cb2-eaa82a6a095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Mapping characters to integers.\n",
    "char_to_num = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=labelNames, mask_token=None)\n",
    "\n",
    "# Mapping integers back to original characters.\n",
    "num_to_char = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02000a51-5b82-4b6c-bcd4-94e5c0c07c71",
   "metadata": {},
   "source": [
    "def process_images_labels(image, label):\n",
    "    return {\"image\": tf.convert_to_tensor(image), \"label\": tf.convert_to_tensor(label)}\n",
    "\n",
    "def prepare_dataset(images, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels)).map(\n",
    "        process_images_labels, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset.batch(128).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e24fd49-cfce-491d-85cf-da72671c8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16a8a4-5dc2-4ec7-b32f-87cbd4ef1ada",
   "metadata": {},
   "source": [
    "train_dataset = prepare_dataset(X_train, y_train)\n",
    "val_dataset = prepare_dataset(X_val, y_val)\n",
    "test_dataset = prepare_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff2d60e-d41f-4260-9e06-d4fe9a000ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"handwriting_recognizer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 36, 36, 1)]       0         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 36, 36, 32)        320       \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 36, 36, 64)        18496     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 36, 2304)          0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 36, 64)            147520    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 36, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 36, 256)          197632    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 36, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 36)                165924    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 694,244\n",
      "Trainable params: 694,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    inp = tf.keras.Input(shape=(36, 36, 1), name=\"image\")\n",
    "\n",
    "    # First conv block.\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv1\",\n",
    "    )(inp)\n",
    "    # x = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "    # Second conv block.\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv2\",\n",
    "    )(x)\n",
    "    # x = tf.keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "\n",
    "    # The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing the output to the RNN part of the model.\n",
    "    new_shape = (36, (36 * 64))\n",
    "    x = tf.keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # RNNs.\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.25)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.25)\n",
    "    )(x)\n",
    "    \n",
    "    # flatten\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(\n",
    "        len(labelNames), activation=\"softmax\", name=\"dense2\"\n",
    "    )(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=inp, outputs=output, name=\"handwriting_recognizer\"\n",
    "    )\n",
    "    # Optimizer.\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    # Compile the model and return.\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get the model.\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9503e34e-2fd1-47c7-984e-ed9a4842e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8849/8849 [==============================] - 150s 16ms/step - loss: 0.1921 - accuracy: 0.9443 - val_loss: 0.1015 - val_accuracy: 0.9710\n",
      "Epoch 2/50\n",
      "8849/8849 [==============================] - 140s 16ms/step - loss: 0.0968 - accuracy: 0.9722 - val_loss: 0.0824 - val_accuracy: 0.9775\n",
      "Epoch 3/50\n",
      "8849/8849 [==============================] - 142s 16ms/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 0.0730 - val_accuracy: 0.9793\n",
      "Epoch 4/50\n",
      "8849/8849 [==============================] - 142s 16ms/step - loss: 0.0663 - accuracy: 0.9799 - val_loss: 0.0655 - val_accuracy: 0.9817\n",
      "Epoch 5/50\n",
      "8849/8849 [==============================] - 138s 16ms/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.0585 - val_accuracy: 0.9834\n",
      "Epoch 6/50\n",
      "8849/8849 [==============================] - 141s 16ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.0649 - val_accuracy: 0.9817\n",
      "Epoch 7/50\n",
      "8849/8849 [==============================] - 137s 15ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
      "Epoch 8/50\n",
      "8849/8849 [==============================] - 148s 17ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0495 - val_accuracy: 0.9864\n",
      "Epoch 9/50\n",
      "8849/8849 [==============================] - 139s 16ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0521 - val_accuracy: 0.9862\n",
      "Epoch 10/50\n",
      "8849/8849 [==============================] - 148s 17ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0514 - val_accuracy: 0.9864\n",
      "Epoch 11/50\n",
      "8849/8849 [==============================] - 147s 17ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.0494 - val_accuracy: 0.9874\n",
      "Epoch 12/50\n",
      "8849/8849 [==============================] - 143s 16ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0490 - val_accuracy: 0.9867\n",
      "Epoch 13/50\n",
      "8849/8849 [==============================] - 145s 16ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0541 - val_accuracy: 0.9867\n",
      "Epoch 14/50\n",
      "8849/8849 [==============================] - 143s 16ms/step - loss: 0.0315 - accuracy: 0.9901 - val_loss: 0.0498 - val_accuracy: 0.9881\n",
      "Epoch 15/50\n",
      "8849/8849 [==============================] - 141s 16ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0489 - val_accuracy: 0.9877\n",
      "Epoch 16/50\n",
      "8849/8849 [==============================] - 144s 16ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0468 - val_accuracy: 0.9885\n",
      "Epoch 17/50\n",
      "8849/8849 [==============================] - 142s 16ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0489 - val_accuracy: 0.9884\n",
      "Epoch 18/50\n",
      "8849/8849 [==============================] - 160s 18ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0507 - val_accuracy: 0.9878\n",
      "Epoch 19/50\n",
      "8849/8849 [==============================] - 167s 19ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
      "Epoch 20/50\n",
      "8849/8849 [==============================] - 156s 18ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0483 - val_accuracy: 0.9886\n",
      "Epoch 21/50\n",
      "8849/8849 [==============================] - 141s 16ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.0486 - val_accuracy: 0.9882\n",
      "Epoch 22/50\n",
      "8849/8849 [==============================] - 147s 17ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0489 - val_accuracy: 0.9886\n",
      "Epoch 23/50\n",
      "8849/8849 [==============================] - 157s 18ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.0492 - val_accuracy: 0.9894\n",
      "Epoch 24/50\n",
      "8849/8849 [==============================] - 158s 18ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0510 - val_accuracy: 0.9881\n",
      "Epoch 25/50\n",
      "8849/8849 [==============================] - 140s 16ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0498 - val_accuracy: 0.9887\n",
      "Epoch 26/50\n",
      "8849/8849 [==============================] - 143s 16ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0490 - val_accuracy: 0.9894\n",
      "Epoch 27/50\n",
      "8849/8849 [==============================] - 139s 16ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0495 - val_accuracy: 0.9891\n",
      "Epoch 28/50\n",
      "8849/8849 [==============================] - 162s 18ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0498 - val_accuracy: 0.9888\n",
      "Epoch 29/50\n",
      "8849/8849 [==============================] - 155s 18ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0501 - val_accuracy: 0.9888\n",
      "Epoch 30/50\n",
      "8849/8849 [==============================] - 146s 17ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0493 - val_accuracy: 0.9897\n",
      "Epoch 31/50\n",
      "8849/8849 [==============================] - 146s 16ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0495 - val_accuracy: 0.9891\n",
      "Epoch 32/50\n",
      "8849/8849 [==============================] - 146s 17ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0490 - val_accuracy: 0.9901\n",
      "Epoch 33/50\n",
      "8849/8849 [==============================] - 146s 17ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9903\n",
      "Epoch 34/50\n",
      "8849/8849 [==============================] - 148s 17ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.0527 - val_accuracy: 0.9894\n",
      "Epoch 35/50\n",
      "8849/8849 [==============================] - 144s 16ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0469 - val_accuracy: 0.9901\n",
      "Epoch 36/50\n",
      "8849/8849 [==============================] - 144s 16ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0524 - val_accuracy: 0.9891\n",
      "Epoch 37/50\n",
      "8849/8849 [==============================] - 146s 16ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0545 - val_accuracy: 0.9887\n",
      "Epoch 38/50\n",
      "8849/8849 [==============================] - 143s 16ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0508 - val_accuracy: 0.9895\n",
      "Epoch 39/50\n",
      "8849/8849 [==============================] - 134s 15ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0519 - val_accuracy: 0.9893\n",
      "Epoch 40/50\n",
      "8849/8849 [==============================] - 143s 16ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0528 - val_accuracy: 0.9890\n",
      "Epoch 41/50\n",
      "8849/8849 [==============================] - 155s 18ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0497 - val_accuracy: 0.9902\n",
      "Epoch 42/50\n",
      "8849/8849 [==============================] - 161s 18ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.0529 - val_accuracy: 0.9891\n",
      "Epoch 43/50\n",
      "8849/8849 [==============================] - 162s 18ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0542 - val_accuracy: 0.9896\n",
      "Epoch 44/50\n",
      "8849/8849 [==============================] - 153s 17ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0489 - val_accuracy: 0.9898\n",
      "Epoch 45/50\n",
      "8849/8849 [==============================] - 155s 17ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0493 - val_accuracy: 0.9899\n",
      "Epoch 46/50\n",
      "8849/8849 [==============================] - 153s 17ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0500 - val_accuracy: 0.9896\n",
      "Epoch 47/50\n",
      "8849/8849 [==============================] - 156s 18ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0485 - val_accuracy: 0.9903\n",
      "Epoch 48/50\n",
      "8849/8849 [==============================] - 151s 17ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0497 - val_accuracy: 0.9894\n",
      "Epoch 49/50\n",
      "8849/8849 [==============================] - 139s 16ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0522 - val_accuracy: 0.9899\n",
      "Epoch 50/50\n",
      "8849/8849 [==============================] - 139s 16ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0500 - val_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "epochs = 50  # To get good results this should be at least 50.\n",
    "\n",
    "model = build_model()\n",
    "prediction_model = tf.keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec90331a-9836-4ebd-b12e-b7459188308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/Complex_Model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7ac842-ae77-4654-8c1b-73049e9f8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('hist/Complex_Model.model', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33685cee-cbf8-4c72-b4ca-3e08af5dcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional model load\n",
    "model = tf.keras.models.load_model('model/Complex_Model.hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7cc87b4-8758-4dd2-9521-d106306e5588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        40\n",
      "           1       0.98      1.00      0.99        64\n",
      "           2       0.98      0.96      0.97        48\n",
      "           3       1.00      1.00      1.00        43\n",
      "           4       0.98      0.98      0.98        50\n",
      "           5       1.00      0.96      0.98        45\n",
      "           6       1.00      1.00      1.00        46\n",
      "           7       1.00      1.00      1.00        46\n",
      "           8       1.00      1.00      1.00        49\n",
      "           9       1.00      0.97      0.99        40\n",
      "           A       0.98      1.00      0.99        90\n",
      "           B       1.00      0.98      0.99        62\n",
      "           C       0.99      1.00      1.00       143\n",
      "           D       0.97      0.99      0.98        72\n",
      "           E       1.00      1.00      1.00        88\n",
      "           F       1.00      1.00      1.00         4\n",
      "           G       0.97      1.00      0.99        34\n",
      "           H       1.00      0.98      0.99        46\n",
      "           I       1.00      1.00      1.00         8\n",
      "           J       0.98      0.97      0.97        59\n",
      "           K       1.00      0.96      0.98        47\n",
      "           L       1.00      0.98      0.99        83\n",
      "           M       1.00      1.00      1.00        81\n",
      "           N       1.00      1.00      1.00       115\n",
      "           O       0.99      0.99      0.99       414\n",
      "           P       1.00      1.00      1.00       138\n",
      "           Q       0.98      0.98      0.98        46\n",
      "           R       0.97      0.99      0.98        67\n",
      "           S       0.99      1.00      1.00       337\n",
      "           T       1.00      1.00      1.00       157\n",
      "           U       0.99      1.00      0.99       197\n",
      "           V       1.00      1.00      1.00        22\n",
      "           W       1.00      0.98      0.99        66\n",
      "           X       1.00      0.98      0.99        42\n",
      "           Y       0.97      1.00      0.99        69\n",
      "           Z       0.95      0.98      0.96        42\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:3000])\n",
    "print(classification_report(y_test[:3000].argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6a2570b-87d8-4caf-be56-b62f7ff76789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7868/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26704dbe970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7868/', None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monol\\anaconda3\\lib\\site-packages\\gradio\\networking.py\", line 237, in predict\n",
      "    prediction, durations = app.interface.process(raw_input)\n",
      "  File \"C:\\Users\\monol\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 411, in process\n",
      "    predictions, durations = self.run_prediction(\n",
      "  File \"C:\\Users\\monol\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 374, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"C:\\Users\\monol\\AppData\\Local\\Temp/ipykernel_20860/3275017357.py\", line 4, in classify\n",
      "    prediction = model.predict(np.pad(input.reshape(28, 28)), ((4,4),(4,4)), mode='constant', constant_values=0).tolist()[0]\n",
      "  File \"<__array_function__ internals>\", line 4, in pad\n",
      "TypeError: _pad_dispatcher() missing 1 required positional argument: 'pad_width'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def classify(input):\n",
    "    prediction = model.predict(np.pad(input.reshape(28, 28)), ((4,4),(4,4)), mode='constant', constant_values=0).tolist()[0]\n",
    "    return {str(label): prediction[i] for i, label in enumerate(labelNames)}\n",
    "\n",
    "label = gr.outputs.Label(num_top_classes=3)\n",
    "interface = gr.Interface(fn=classify, inputs=\"sketchpad\", outputs=label)\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a2641-4ba7-409a-bf10-75edbdc36565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
